/*

     FFTE: A FAST FOURIER TRANSFORM PACKAGE

     (C) COPYRIGHT SOFTWARE, 2000-2004, 2008-2014, ALL RIGHTS RESERVED
                BY
         DAISUKE TAKAHASHI
         FACULTY OF ENGINEERING, INFORMATION AND SYSTEMS
         UNIVERSITY OF TSUKUBA
         1-1-1 TENNODAI, TSUKUBA, IBARAKI 305-8573, JAPAN
         E-MAIL: daisuke@cs.tsukuba.ac.jp


     WRITTEN BY DAISUKE TAKAHASHI

     THIS KERNEL WAS GENERATED BY SPIRAL 8.2.0a03
*/

#include <arm_sve.h>

void dft10c_(float64_t  *Y, float64_t  *X, int  *lp1, int  *mp1) {
    int l1, m1;
    svfloat64x2_t s512, s515, s518, s521, s524, s527, s530, s533, 
            s536, s539, svex2_11, svex2_12, svex2_13, svex2_14, svex2_15, svex2_16, 
            svex2_17, svex2_18, svex2_19, svex2_20;
    svfloat64_t s513, s514, s516, s517, s519, s520, s522, s523, 
            s525, s526, s528, s529, s531, s532, s534, s535, 
            s537, s538, s540, s541, s542, s543, s544, s545, 
            s546, s547, s548, s549, s550, s551, s552, s553, 
            s554, s555, s556, s557, s558, s559, s560, s561, 
            s562, s563, s564, s565, s566, s567, s568, s569, 
            s570, s571, s572, s573, s574, s575, s576, s577, 
            t1310, t1311, t1312, t1313, t1314, t1315, t1316, t1317, 
            t1318, t1319, t1320, t1321, t1322, t1323, t1324, t1325, 
            t1326, t1327, t1328, t1329, t1330, t1331, t1332, t1333, 
            t1334, t1335, t1336, t1337, t1338, t1339, t1340, t1341, 
            t1342, t1343, t1344, t1345, t1346, t1347, t1348, t1349, 
            t1350, t1351, t1352, t1353, t1354, t1355, t1356, t1357, 
            t1358, t1359, t1360, t1361, t1362, t1363, t1364, t1365, 
            t1366, t1367, t1368, t1369, t1370, t1371, t1372, t1373, 
            t1374, t1375, t1376, t1377;
    svbool_t pg1;
    l1 = *(lp1);
    m1 = *(mp1);
    int k1 = 0;
    pg1 = svwhilelt_b64(k1, m1);
    do {
        s512 = svld2_f64(pg1, (X + ((2)*(k1))));
        s513 = s512.v0;
        s514 = s512.v1;
        s515 = svld2_f64(pg1, (X + ((2)*((k1 + ((l1)*(m1)))))));
        s516 = s515.v0;
        s517 = s515.v1;
        s518 = svld2_f64(pg1, (X + ((2)*((k1 + ((((2)*(l1)))*(m1)))))));
        s519 = s518.v0;
        s520 = s518.v1;
        s521 = svld2_f64(pg1, (X + ((2)*((k1 + ((((3)*(l1)))*(m1)))))));
        s522 = s521.v0;
        s523 = s521.v1;
        s524 = svld2_f64(pg1, (X + ((2)*((k1 + ((((4)*(l1)))*(m1)))))));
        s525 = s524.v0;
        s526 = s524.v1;
        s527 = svld2_f64(pg1, (X + ((2)*((k1 + ((((5)*(l1)))*(m1)))))));
        s528 = s527.v0;
        s529 = s527.v1;
        s530 = svld2_f64(pg1, (X + ((2)*((k1 + ((((6)*(l1)))*(m1)))))));
        s531 = s530.v0;
        s532 = s530.v1;
        s533 = svld2_f64(pg1, (X + ((2)*((k1 + ((((7)*(l1)))*(m1)))))));
        s534 = s533.v0;
        s535 = s533.v1;
        s536 = svld2_f64(pg1, (X + ((2)*((k1 + ((((8)*(l1)))*(m1)))))));
        s537 = s536.v0;
        s538 = s536.v1;
        s539 = svld2_f64(pg1, (X + ((2)*((k1 + ((((9)*(l1)))*(m1)))))));
        s540 = s539.v0;
        s541 = s539.v1;
        t1310 = svadd_f64_x(pg1, s519, s537);
        t1311 = svadd_f64_x(pg1, s520, s538);
        t1312 = svsub_f64_x(pg1, s519, s537);
        t1313 = svsub_f64_x(pg1, s520, s538);
        t1314 = svadd_f64_x(pg1, s525, s531);
        t1315 = svadd_f64_x(pg1, s526, s532);
        t1316 = svsub_f64_x(pg1, s525, s531);
        t1317 = svsub_f64_x(pg1, s526, s532);
        t1318 = svadd_f64_x(pg1, t1310, t1314);
        t1319 = svadd_f64_x(pg1, t1311, t1315);
        t1320 = svadd_f64_x(pg1, t1312, t1317);
        t1321 = svsub_f64_x(pg1, t1313, t1316);
        t1322 = svsub_f64_x(pg1, t1312, t1317);
        t1323 = svadd_f64_x(pg1, t1313, t1316);
        t1324 = svadd_f64_x(pg1, s513, t1318);
        t1325 = svadd_f64_x(pg1, s514, t1319);
        t1326 = svmls_n_f64_x(pg1, s513, t1318, 0.25);
        t1327 = svmls_n_f64_x(pg1, s514, t1319, 0.25);
        s562 = svmla_n_f64_x(pg1, t1320, t1321, 1.6180339887498947);
        s542 = svmul_n_f64_x(pg1, s562, 0.29389262614623657);
        s563 = svmls_n_f64_x(pg1, t1321, t1320, 1.6180339887498947);
        s543 = svmul_n_f64_x(pg1, s563, 0.29389262614623657);
        s544 = svmul_n_f64_x(pg1, svsub_f64_x(pg1, t1310, t1314), 0.55901699437494745);
        s545 = svmul_n_f64_x(pg1, svsub_f64_x(pg1, t1311, t1315), 0.55901699437494745);
        s564 = svmls_n_f64_x(pg1, t1323, t1322, 0.61803398874989479);
        s546 = svmul_n_f64_x(pg1, s564, 0.47552825814757682);
        s565 = svmla_n_f64_x(pg1, t1322, t1323, 0.61803398874989479);
        s547 = svmul_n_f64_x(pg1, s565, 0.47552825814757682);
        t1328 = svadd_f64_x(pg1, t1326, s544);
        t1329 = svadd_f64_x(pg1, t1327, s545);
        t1330 = svsub_f64_x(pg1, t1326, s544);
        t1331 = svsub_f64_x(pg1, t1327, s545);
        t1332 = svadd_f64_x(pg1, s542, s546);
        t1333 = svsub_f64_x(pg1, s543, s547);
        t1334 = svsub_f64_x(pg1, s542, s546);
        t1335 = svadd_f64_x(pg1, s543, s547);
        t1336 = svadd_f64_x(pg1, t1328, t1332);
        t1337 = svadd_f64_x(pg1, t1329, t1333);
        t1338 = svsub_f64_x(pg1, t1328, t1332);
        t1339 = svsub_f64_x(pg1, t1329, t1333);
        t1340 = svadd_f64_x(pg1, t1330, t1335);
        t1341 = svsub_f64_x(pg1, t1331, t1334);
        t1342 = svsub_f64_x(pg1, t1330, t1335);
        t1343 = svadd_f64_x(pg1, t1331, t1334);
        t1344 = svadd_f64_x(pg1, s522, s540);
        t1345 = svadd_f64_x(pg1, s523, s541);
        t1346 = svsub_f64_x(pg1, s522, s540);
        t1347 = svsub_f64_x(pg1, s523, s541);
        t1348 = svadd_f64_x(pg1, s528, s534);
        t1349 = svadd_f64_x(pg1, s529, s535);
        t1350 = svsub_f64_x(pg1, s528, s534);
        t1351 = svsub_f64_x(pg1, s529, s535);
        t1352 = svadd_f64_x(pg1, t1344, t1348);
        t1353 = svadd_f64_x(pg1, t1345, t1349);
        t1354 = svadd_f64_x(pg1, t1346, t1351);
        t1355 = svsub_f64_x(pg1, t1347, t1350);
        t1356 = svsub_f64_x(pg1, t1346, t1351);
        t1357 = svadd_f64_x(pg1, t1347, t1350);
        t1358 = svadd_f64_x(pg1, s516, t1352);
        t1359 = svadd_f64_x(pg1, s517, t1353);
        t1360 = svmls_n_f64_x(pg1, s516, t1352, 0.25);
        t1361 = svmls_n_f64_x(pg1, s517, t1353, 0.25);
        s566 = svmla_n_f64_x(pg1, t1354, t1355, 1.6180339887498947);
        s548 = svmul_n_f64_x(pg1, s566, 0.29389262614623657);
        s567 = svmls_n_f64_x(pg1, t1355, t1354, 1.6180339887498947);
        s549 = svmul_n_f64_x(pg1, s567, 0.29389262614623657);
        s550 = svmul_n_f64_x(pg1, svsub_f64_x(pg1, t1344, t1348), 0.55901699437494745);
        s551 = svmul_n_f64_x(pg1, svsub_f64_x(pg1, t1345, t1349), 0.55901699437494745);
        s568 = svmls_n_f64_x(pg1, t1357, t1356, 0.61803398874989479);
        s552 = svmul_n_f64_x(pg1, s568, 0.47552825814757682);
        s569 = svmla_n_f64_x(pg1, t1356, t1357, 0.61803398874989479);
        s553 = svmul_n_f64_x(pg1, s569, 0.47552825814757682);
        t1362 = svadd_f64_x(pg1, t1360, s550);
        t1363 = svadd_f64_x(pg1, t1361, s551);
        t1364 = svsub_f64_x(pg1, t1360, s550);
        t1365 = svsub_f64_x(pg1, t1361, s551);
        t1366 = svadd_f64_x(pg1, s548, s552);
        t1367 = svsub_f64_x(pg1, s549, s553);
        t1368 = svsub_f64_x(pg1, s548, s552);
        t1369 = svadd_f64_x(pg1, s549, s553);
        t1370 = svadd_f64_x(pg1, t1362, t1366);
        t1371 = svadd_f64_x(pg1, t1363, t1367);
        t1372 = svsub_f64_x(pg1, t1362, t1366);
        t1373 = svsub_f64_x(pg1, t1363, t1367);
        s570 = svmla_n_f64_x(pg1, t1370, t1371, 0.7265425280053609);
        s554 = svmul_n_f64_x(pg1, s570, 0.80901699437494745);
        s571 = svmls_n_f64_x(pg1, t1371, t1370, 0.7265425280053609);
        s555 = svmul_n_f64_x(pg1, s571, 0.80901699437494745);
        s572 = svmls_n_f64_x(pg1, t1373, t1372, 1.3763819204711736);
        s556 = svmul_n_f64_x(pg1, s572, 0.58778525229247314);
        s573 = svmla_n_f64_x(pg1, t1372, t1373, 1.3763819204711736);
        s557 = svmul_n_f64_x(pg1, s573, 0.58778525229247314);
        t1374 = svadd_f64_x(pg1, t1364, t1369);
        t1375 = svsub_f64_x(pg1, t1365, t1368);
        t1376 = svsub_f64_x(pg1, t1364, t1369);
        t1377 = svadd_f64_x(pg1, t1365, t1368);
        s574 = svmla_n_f64_x(pg1, t1374, t1375, 3.0776835371752536);
        s558 = svmul_n_f64_x(pg1, s574, 0.3090169943749474);
        s575 = svmls_n_f64_x(pg1, t1375, t1374, 3.0776835371752536);
        s559 = svmul_n_f64_x(pg1, s575, 0.3090169943749474);
        s576 = svmls_n_f64_x(pg1, t1377, t1376, 0.32491969623290629);
        s560 = svmul_n_f64_x(pg1, s576, 0.95105651629515353);
        s577 = svmla_n_f64_x(pg1, t1376, t1377, 0.32491969623290629);
        s561 = svmul_n_f64_x(pg1, s577, 0.95105651629515353);
        svex2_11.v0 = svadd_f64_x(pg1, t1324, t1358);
        svex2_11.v1 = svadd_f64_x(pg1, t1325, t1359);
        svst2_f64(pg1, (Y + ((2)*(k1))), svex2_11);
        svex2_12.v0 = svadd_f64_x(pg1, t1336, s554);
        svex2_12.v1 = svadd_f64_x(pg1, t1337, s555);
        svst2_f64(pg1, (Y + ((2)*((k1 + m1)))), svex2_12);
        svex2_13.v0 = svadd_f64_x(pg1, t1340, s558);
        svex2_13.v1 = svadd_f64_x(pg1, t1341, s559);
        svst2_f64(pg1, (Y + ((2)*((k1 + ((2)*(m1)))))), svex2_13);
        svex2_14.v0 = svadd_f64_x(pg1, t1342, s560);
        svex2_14.v1 = svsub_f64_x(pg1, t1343, s561);
        svst2_f64(pg1, (Y + ((2)*((k1 + ((3)*(m1)))))), svex2_14);
        svex2_15.v0 = svadd_f64_x(pg1, t1338, s556);
        svex2_15.v1 = svsub_f64_x(pg1, t1339, s557);
        svst2_f64(pg1, (Y + ((2)*((k1 + ((4)*(m1)))))), svex2_15);
        svex2_16.v0 = svsub_f64_x(pg1, t1324, t1358);
        svex2_16.v1 = svsub_f64_x(pg1, t1325, t1359);
        svst2_f64(pg1, (Y + ((2)*((k1 + ((5)*(m1)))))), svex2_16);
        svex2_17.v0 = svsub_f64_x(pg1, t1336, s554);
        svex2_17.v1 = svsub_f64_x(pg1, t1337, s555);
        svst2_f64(pg1, (Y + ((2)*((k1 + ((6)*(m1)))))), svex2_17);
        svex2_18.v0 = svsub_f64_x(pg1, t1340, s558);
        svex2_18.v1 = svsub_f64_x(pg1, t1341, s559);
        svst2_f64(pg1, (Y + ((2)*((k1 + ((7)*(m1)))))), svex2_18);
        svex2_19.v0 = svsub_f64_x(pg1, t1342, s560);
        svex2_19.v1 = svadd_f64_x(pg1, t1343, s561);
        svst2_f64(pg1, (Y + ((2)*((k1 + ((8)*(m1)))))), svex2_19);
        svex2_20.v0 = svsub_f64_x(pg1, t1338, s556);
        svex2_20.v1 = svadd_f64_x(pg1, t1339, s557);
        svst2_f64(pg1, (Y + ((2)*((k1 + ((9)*(m1)))))), svex2_20);
        k1 += svcntd();
        pg1 = svwhilelt_b64(k1, m1);
    } while(svptest_any(svptrue_b64(), pg1));
}
