/*

     FFTE: A FAST FOURIER TRANSFORM PACKAGE

     (C) COPYRIGHT SOFTWARE, 2000-2004, 2008-2014, ALL RIGHTS RESERVED
                BY
         DAISUKE TAKAHASHI
         FACULTY OF ENGINEERING, INFORMATION AND SYSTEMS
         UNIVERSITY OF TSUKUBA
         1-1-1 TENNODAI, TSUKUBA, IBARAKI 305-8573, JAPAN
         E-MAIL: daisuke@cs.tsukuba.ac.jp


     WRITTEN BY DAISUKE TAKAHASHI

     THIS KERNEL WAS GENERATED BY SPIRAL 8.2.0a03
*/

#include <arm_sve.h>

void dft6b_(float64_t  *Y, float64_t  *X, float64_t  *TW1, int  *lp1, int  *mp1) {
    float64_t a551, a552, a553, a554, a555, a556, a557, a558, 
            a559, a560;
    int a549, a550, j1, l1, m1;
    svfloat64x2_t s277, s280, s283, s286, s289, s292, svex2_10, svex2_11, 
            svex2_12, svex2_7, svex2_8, svex2_9;
    svfloat64_t s278, s279, s281, s282, s284, s285, s287, s288, 
            s290, s291, s293, s294, s295, s296, s297, s298, 
            s299, s300, s301, s302, s303, s304, s305, s306, 
            s307, s308, s309, s310, s311, s312, s313, s314, 
            s315, s316, t495, t496, t497, t498, t499, t500, 
            t501, t502, t503, t504, t505, t506, t507, t508, 
            t509, t510, t511, t512, t513, t514;
    svbool_t pg1;
    l1 = *(lp1);
    m1 = *(mp1);
    for(int j2 = 0; j2 < (l1 - 1); j2++) {
        j1 = (j2 + 1);
        int k1 = 0;
        pg1 = svwhilelt_b64(k1, m1);
        do {
            a549 = (k1 + ((j1)*(m1)));
            s277 = svld2_f64(pg1, (X + ((2)*(a549))));
            s278 = s277.v0;
            s279 = s277.v1;
            s280 = svld2_f64(pg1, (X + ((2)*((a549 + ((l1)*(m1)))))));
            s281 = s280.v0;
            s282 = s280.v1;
            s283 = svld2_f64(pg1, (X + ((2)*((a549 + ((((2)*(l1)))*(m1)))))));
            s284 = s283.v0;
            s285 = s283.v1;
            s286 = svld2_f64(pg1, (X + ((2)*((a549 + ((((3)*(l1)))*(m1)))))));
            s287 = s286.v0;
            s288 = s286.v1;
            s289 = svld2_f64(pg1, (X + ((2)*((a549 + ((((4)*(l1)))*(m1)))))));
            s290 = s289.v0;
            s291 = s289.v1;
            s292 = svld2_f64(pg1, (X + ((2)*((a549 + ((((5)*(l1)))*(m1)))))));
            s293 = s292.v0;
            s294 = s292.v1;
            t495 = svadd_f64_x(pg1, s284, s290);
            t496 = svadd_f64_x(pg1, s285, s291);
            t497 = svadd_f64_x(pg1, s278, t495);
            t498 = svadd_f64_x(pg1, s279, t496);
            t499 = svmls_n_f64_x(pg1, s278, t495, 0.5);
            t500 = svmls_n_f64_x(pg1, s279, t496, 0.5);
            s295 = svmul_n_f64_x(pg1, svsub_f64_x(pg1, s285, s291), 0.8660254037844386);
            s296 = svmul_n_f64_x(pg1, svsub_f64_x(pg1, s284, s290), 0.8660254037844386);
            t501 = svadd_f64_x(pg1, t499, s295);
            t502 = svsub_f64_x(pg1, t500, s296);
            t503 = svsub_f64_x(pg1, t499, s295);
            t504 = svadd_f64_x(pg1, t500, s296);
            t505 = svadd_f64_x(pg1, s287, s293);
            t506 = svadd_f64_x(pg1, s288, s294);
            t507 = svadd_f64_x(pg1, s281, t505);
            t508 = svadd_f64_x(pg1, s282, t506);
            t509 = svmls_n_f64_x(pg1, s281, t505, 0.5);
            t510 = svmls_n_f64_x(pg1, s282, t506, 0.5);
            s297 = svmul_n_f64_x(pg1, svsub_f64_x(pg1, s288, s294), 0.8660254037844386);
            s298 = svmul_n_f64_x(pg1, svsub_f64_x(pg1, s287, s293), 0.8660254037844386);
            t511 = svadd_f64_x(pg1, t509, s297);
            t512 = svsub_f64_x(pg1, t510, s298);
            t513 = svsub_f64_x(pg1, t509, s297);
            t514 = svadd_f64_x(pg1, t510, s298);
            s313 = svmla_n_f64_x(pg1, t511, t512, 1.7320508075688772);
            s299 = svmul_n_f64_x(pg1, s313, 0.5);
            s314 = svmls_n_f64_x(pg1, t512, t511, 1.7320508075688772);
            s300 = svmul_n_f64_x(pg1, s314, 0.5);
            s315 = svmls_n_f64_x(pg1, t514, t513, 0.57735026918962584);
            s301 = svmul_n_f64_x(pg1, s315, 0.8660254037844386);
            s316 = svmla_n_f64_x(pg1, t513, t514, 0.57735026918962584);
            s302 = svmul_n_f64_x(pg1, s316, 0.8660254037844386);
            s303 = svsub_f64_x(pg1, t497, t507);
            s304 = svsub_f64_x(pg1, t498, t508);
            s305 = svadd_f64_x(pg1, t501, s299);
            s306 = svadd_f64_x(pg1, t502, s300);
            s307 = svsub_f64_x(pg1, t501, s299);
            s308 = svsub_f64_x(pg1, t502, s300);
            s309 = svadd_f64_x(pg1, t503, s301);
            s310 = svsub_f64_x(pg1, t504, s302);
            s311 = svsub_f64_x(pg1, t503, s301);
            s312 = svadd_f64_x(pg1, t504, s302);
            a550 = ((10)*(j1));
            a551 = TW1[a550];
            a552 = TW1[(a550 + 1)];
            a553 = TW1[(a550 + 2)];
            a554 = TW1[(a550 + 3)];
            a555 = TW1[(a550 + 4)];
            a556 = TW1[(a550 + 5)];
            a557 = TW1[(a550 + 6)];
            a558 = TW1[(a550 + 7)];
            a559 = TW1[(a550 + 8)];
            a560 = TW1[(a550 + 9)];
            svex2_7.v0 = svadd_f64_x(pg1, t497, t507);
            svex2_7.v1 = svadd_f64_x(pg1, t498, t508);
            svst2_f64(pg1, (Y + ((2)*((k1 + ((((6)*(j1)))*(m1)))))), svex2_7);
            svex2_8.v0 = svnmls_n_f64_x(pg1, svmul_n_f64_x(pg1, s306, a552), s305, a551);
            svex2_8.v1 = svmla_n_f64_x(pg1, svmul_n_f64_x(pg1, s306, a551), s305, a552);
            svst2_f64(pg1, (Y + ((2)*((k1 + ((((6)*(j1)))*(m1)) + m1)))), svex2_8);
            svex2_9.v0 = svnmls_n_f64_x(pg1, svmul_n_f64_x(pg1, s310, a554), s309, a553);
            svex2_9.v1 = svmla_n_f64_x(pg1, svmul_n_f64_x(pg1, s310, a553), s309, a554);
            svst2_f64(pg1, (Y + ((2)*((k1 + ((((6)*(j1)))*(m1)) + ((2)*(m1)))))), svex2_9);
            svex2_10.v0 = svnmls_n_f64_x(pg1, svmul_n_f64_x(pg1, s304, a556), s303, a555);
            svex2_10.v1 = svmla_n_f64_x(pg1, svmul_n_f64_x(pg1, s304, a555), s303, a556);
            svst2_f64(pg1, (Y + ((2)*((k1 + ((((6)*(j1)))*(m1)) + ((3)*(m1)))))), svex2_10);
            svex2_11.v0 = svnmls_n_f64_x(pg1, svmul_n_f64_x(pg1, s308, a558), s307, a557);
            svex2_11.v1 = svmla_n_f64_x(pg1, svmul_n_f64_x(pg1, s308, a557), s307, a558);
            svst2_f64(pg1, (Y + ((2)*((k1 + ((((6)*(j1)))*(m1)) + ((4)*(m1)))))), svex2_11);
            svex2_12.v0 = svnmls_n_f64_x(pg1, svmul_n_f64_x(pg1, s312, a560), s311, a559);
            svex2_12.v1 = svmla_n_f64_x(pg1, svmul_n_f64_x(pg1, s312, a559), s311, a560);
            svst2_f64(pg1, (Y + ((2)*((k1 + ((((6)*(j1)))*(m1)) + ((5)*(m1)))))), svex2_12);
            k1 += svcntd();
            pg1 = svwhilelt_b64(k1, m1);
        } while(svptest_any(svptrue_b64(), pg1));
    }
}
